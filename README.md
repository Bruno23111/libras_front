
-----

# Libras.IO - Tradutor de Libras Interativo

Um projeto web que combina Vis√£o Computacional (TensorFlow.js e MediaPipe) e IA Generativa (Google Gemini) para criar uma ferramenta completa de aprendizado e tradu√ß√£o da L√≠ngua Brasileira de Sinais (Libras).

-----

## üìö Sobre o Projeto

O **Libras.IO** foi criado como uma ponte de comunica√ß√£o acess√≠vel, utilizando o poder de tr√™s diferentes tipos de Intelig√™ncia Artificial diretamente no navegador. O objetivo √© fornecer uma ferramenta de aprendizado interativa onde os usu√°rios podem praticar o alfabeto, aprender palavras e tirar d√∫vidas sobre a cultura Surda em um s√≥ lugar.

A aplica√ß√£o √© dividida em quatro abas principais:

1.  **Introdu√ß√£o:** Apresenta o projeto e seus objetivos.
2.  **Alfabeto:** Utiliza TensorFlow.js para classificar sinais est√°ticos do alfabeto de Libras em tempo real.
3.  **Palavras:** Utiliza MediaPipe HandLandmarker para reconhecer gestos e palavras simples.
4.  **Assistente IA:** Um chatbot com Google Gemini para responder perguntas sobre gram√°tica, hist√≥ria e cultura Surda.

## ‚ú® Funcionalidades Principais

  * **Tradu√ß√£o do Alfabeto:** Classifica√ß√£o de imagem em tempo real (20 letras do alfabeto) usando uma webcam e TensorFlow.js.
  * **Tradu√ß√£o de Palavras:** Reconhecimento de gestos e palavras simples (como "Oi", "Comer", "Pensar") usando MediaPipe.
  * **Assistente Generativo:** Um chatbot inteligente para tirar d√∫vidas contextuais sobre Libras, alimentado pela API Gemini.
  * **Interface Reativa:** Uma interface de usu√°rio limpa, responsiva (mobile-first) e moderna constru√≠da com Tailwind CSS.
  * **Acessibilidade:** Integra√ß√£o com o widget **VLibras** para tradu√ß√£o de texto-para-Libras (Avatar 3D) em toda a p√°gina.

## üõ†Ô∏è Tecnologias Utilizadas

  * **Frontend:** HTML5, CSS3, JavaScript (ES6 Modules)
  * **Estiliza√ß√£o:** [Tailwind CSS](https://tailwindcss.com/) (via CDN)
  * **Fontes:** [Google Fonts](https://fonts.google.com/) (Inter)
  * **IA (Alfabeto):** [TensorFlow.js](https://www.tensorflow.org/js) (`tf.loadLayersModel`)
  * **IA (Palavras):** [MediaPipe](https://developers.google.com/mediapipe) (`HandLandmarker`)
  * **IA (Assistente):** [Google Gemini API](https://ai.google.dev/) (modelo `gemini-2.5-flash-preview-09-2025`)
  * **Acessibilidade:** [VLibras Widget](https://www.google.com/search?q=https://www.gov.br/vlibras/)

-----

## üß† Arquitetura e Funcionamento T√©cnico

O projeto √© modularizado em `script.js` e se baseia em tr√™s pilares de IA independentes que s√£o ativados conforme a navega√ß√£o do usu√°rio.

### 1\. Aba "Alfabeto" (TensorFlow.js - Classifica√ß√£o)

Esta aba usa um modelo de classifica√ß√£o de imagem treinado (presumivelmente em Keras/Python e convertido para web).

  * **Modelo:** Carregado a partir de `./modelos_web/model.json`.
  * **Tecnologia:** `tf.loadLayersModel` do TensorFlow.js.
  * **Fluxo de Execu√ß√£o:**
    1.  Ao abrir a aba, `initAlfabeto()` carrega o modelo e `startWebcamAlfabeto()` ativa a c√¢mera.
    2.  A fun√ß√£o `drawOverlayAlfabeto()` desenha uma caixa-guia tracejada (bounding box) no canvas sobre o v√≠deo.
    3.  O loop `predictLoopAlfabeto()` √© executado a cada frame:
    4.  O frame de v√≠deo √© capturado com `tf.browser.fromPixels`.
    5.  A imagem √© "cortada" (`tf.image.cropAndResize`) para a regi√£o da caixa-guia.
    6.  A imagem cortada √© redimensionada para 128x128 pixels e normalizada (dividida por 255.0).
    7.  A previs√£o (`modelAlfabeto.predict()`) √© executada.
  * **Otimiza√ß√£o (Suaviza√ß√£o):** A fun√ß√£o `smoothPredictionAlfabeto()` armazena as √∫ltimas 5 predi√ß√µes. Ela retorna apenas a letra que mais apareceu nessa "janela", evitando que o resultado "pisque" e tornando a UI mais est√°vel.

### 2\. Aba "Palavras" (MediaPipe - Dete√ß√£o de Gestos)

Esta aba usa o modelo `HandLandmarker` pr√©-treinado do Google para detec√ß√£o de pontos-chave da m√£o (landmarks). A l√≥gica de reconhecimento de gestos √© customizada.

  * **Modelo:** `hand_landmarker.task` (carregado da CDN do Google/MediaPipe).
  * **Tecnologia:** `HandLandmarker` e `DrawingUtils` do `@mediapipe/tasks-vision`.
  * **Fluxo de Execu√ß√£o:**
    1.  `initPalavras()` carrega o `FilesetResolver` e cria o `HandLandmarker` (tentando usar `GPU` com fallback para `CPU`).
    2.  O loop `predictLoopPalavras()` detecta as m√£os no v√≠deo (`handLandmarker.detectForVideo()`).
    3.  `DrawingUtils` √© usado para desenhar o "esqueleto" da m√£o no canvas (`output_canvas_palavras`).
    4.  Os 21 *landmarks* (pontos-chave) da m√£o detectada s√£o passados para a fun√ß√£o `recognizeGestureWord()`.
    5.  Esta fun√ß√£o customizada usa l√≥gica baseada em posi√ß√µes relativas (ex: `isThumbUp`, `isIndexUp`) e dist√¢ncia euclidiana entre os pontos (ex: `getDistance(thumbTip, indexTip)`) para classificar o gesto em uma palavra (ex: "Legal / Bom", "Comer", "Pensar").

### 3\. Aba "Assistente IA" (Google Gemini - IA Generativa)

Esta aba fornece um chatbot para responder perguntas usando um modelo de linguagem grande (LLM).

  * **Modelo:** `gemini-2.5-flash-preview-09-2025` (via API).
  * **Tecnologia:** Chamada `fetch` direta para a API `generativelanguage.googleapis.com`.
  * **Fluxo de Execu√ß√£o:**
    1.  Quando o usu√°rio envia uma mensagem (`handleChatSubmit`), ela √© adicionada a um array local `chatHistory`.
    2.  Uma chamada `POST` √© feita para a API.
    3.  **Contexto (System Prompt):** A requisi√ß√£o inclui uma `systemInstruction` que define a persona da IA: *"Voc√™ √© o 'Libras.IO', um assistente de IA amig√°vel, especialista e entusiasta da L√≠ngua Brasileira de Sinais (Libras)..."*
    4.  **Mem√≥ria:** O array `chatHistory` completo √© enviado no corpo da requisi√ß√£o (`contents`), permitindo que a IA mantenha o contexto da conversa.
    5.  A resposta de texto da IA √© recebida, formatada (Markdown para HTML) e exibida no chat.

### 4\. Gerenciamento de C√¢mera (Ponto Cr√≠tico)

Para evitar conflitos de hardware (duas abas tentando usar a c√¢mera ao mesmo tempo), foi implementada uma l√≥gica de gerenciamento no `script.js`:

  * A fun√ß√£o `openTab(tabId)` primeiro chama `stopAllStreams()`.
  * `stopAllStreams()` desliga **todas** as trilhas de v√≠deo (`track.stop()`) de ambos os streams (Alfabeto e Palavras) e remove a fonte (`srcObject`) dos elementos de v√≠deo.
  * Somente **depois** de desligar tudo, a fun√ß√£o liga a c√¢mera espec√≠fica necess√°ria para a aba que foi clicada (`startWebcamAlfabeto()` ou `setupCameraPalavras()`).

-----

## üöÄ Como Executar o Projeto Localmente

Devido √†s pol√≠ticas de seguran√ßa do navegador (CORS) para carregar modelos (`.json`) e o uso de M√≥dulos JS (`import`), voc√™ **n√£o pode** simplesmente abrir o `index.html` a partir do arquivo. Voc√™ precisa servi-lo a partir de um servidor web local.

### Pr√©-requisitos

1.  Um servidor web local. O mais simples √© usar a extens√£o **Live Server** no VS Code, ou o m√≥dulo `http.server` do Python.
2.  A pasta `modelos_web/` contendo os arquivos `model.json` e `weights.bin` do seu modelo de Alfabeto.
3.  Uma **Chave de API** do [Google AI Studio](https://aistudio.google.com/app/apikey) para o Gemini.

### Passos

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone [URL_DO_SEU_REPOSITORIO]
    cd [NOME_DA_PASTA]
    ```

2.  **Adicione seu modelo:**
    Certifique-se de que sua pasta `modelos_web/` (com os arquivos do modelo TF.js) esteja na raiz do projeto.

3.  **Adicione a Chave da API:**
    Abra o arquivo `script.js` e localize a **Linha 461** (aproximadamente). Substitua o valor da constante `API_KEY` pela sua chave:

    ```javascript
    // Linha 461 em script.js
    const API_KEY = "SUA_CHAVE_DA_API_DO_GEMINI_VEM_AQUI";
    ```

4.  **Inicie o servidor local:**
    Se voc√™ tiver o Python instalado, o m√©todo mais f√°cil √©:

    ```bash
    # Para Python 3.x
    python -m http.server
    ```

    Alternativamente, use o **Live Server** do VS Code clicando em "Go Live".

5.  **Acesse o projeto:**
    Abra seu navegador e acesse `http://localhost:8000` (ou a porta que seu servidor indicar).

-----

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
